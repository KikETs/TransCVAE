{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b75b90d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import pandas as pd\n",
    "from psmiles import PolymerSmiles as PS\n",
    "from torch.utils.data import DataLoader, Dataset, random_split, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerDecoder, TransformerDecoderLayer, TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.nn import MSELoss\n",
    "from torch.nn import HuberLoss\n",
    "from torch.optim import AdamW\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "log_transformer = FunctionTransformer(np.log1p, validate=True)\n",
    "log_minmax_pipeline = Pipeline(steps=[\n",
    "    ('log', log_transformer),\n",
    "    ('minmax', MinMaxScaler())\n",
    "])\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "mm = MinMaxScaler()\n",
    "log_minmax_pipeline2 = Pipeline(steps=[\n",
    "    ('log', log_transformer),\n",
    "    ('minmax', MinMaxScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e351b973",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolymerDataset(Dataset):\n",
    "    def __init__(self, csv_path, mm, log_minmax):\n",
    "        \"\"\"\n",
    "        csv_path: SMILES와 속성(dp, cond)이 담긴 CSV 경로\n",
    "        mm: sklearn MinMaxScaler (dp에 사용)\n",
    "        log_minmax: sklearn MinMaxScaler (cond에 사용)\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(csv_path)\n",
    "        # ── 1) dp / cond 스케일링 → [N,1]\n",
    "        dp_vals = df.iloc[:, 4].values.reshape(-1,1)\n",
    "        cond_vals = df.iloc[:, 6].values.reshape(-1,1)\n",
    "\n",
    "        self.dp = torch.tensor(mm.fit_transform(dp_vals),   dtype=torch.float32).unsqueeze(-1)\n",
    "        self.cond = torch.tensor(log_minmax.fit_transform(cond_vals), dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "        # ── 2) SMILES 전처리 → One-hot 시퀀스\n",
    "        raw_smiles = df.iloc[:,1].tolist()\n",
    "        self.vocab = list(\"CHNOPSFIBrClc()[]=#@*+-1234567890\") + [\"_\"]\n",
    "        self.c2i   = {c:i for i,c in enumerate(self.vocab)}\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.max_len    = max(len(s) for s in raw_smiles)\n",
    "\n",
    "        self.sequences = []\n",
    "        for s in raw_smiles:\n",
    "            idxs = self._smiles_to_idx(s)\n",
    "            oh   = F.one_hot(idxs, num_classes=self.vocab_size).float()\n",
    "            self.sequences.append(oh)\n",
    "\n",
    "    def _smiles_to_idx(self, s: str):\n",
    "        arr = torch.full((self.max_len,), self.c2i[\"_\"], dtype=torch.long)\n",
    "        for i, ch in enumerate(s):\n",
    "            arr[i] = self.c2i.get(ch, self.c2i[\"_\"])\n",
    "        return arr\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # seq_onehot: [max_len, vocab_size], dec: [2,1]\n",
    "        return self.sequences[idx], self.dp[idx], self.cond[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f17dabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Polymers = \"simulation-trajectory-aggregate_aligned.csv\"\n",
    "dataset = PolymerDataset(Polymers, mm, log_minmax_pipeline)\n",
    "\n",
    "train_dataloader = DataLoader(dataset, batch_size=256, shuffle=True, drop_last=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4059e1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div = torch.exp(torch.arange(0, d_model, 2).float()\n",
    "                        * (-math.log(10000.0) / d_model))\n",
    "        pe[:,0::2] = torch.sin(pos * div)\n",
    "        pe[:,1::2] = torch.cos(pos * div)\n",
    "        pe = pe.unsqueeze(0).transpose(0,1)  # [max_len,1,d_model]\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, T, d_model]\n",
    "        x = x + self.pe[:x.size(1)].permute(1,0,2)\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "\n",
    "class TF(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        d_model=256,\n",
    "        n_heads=4,\n",
    "        d_ff=1024,\n",
    "        enc_seq_len=5000,\n",
    "        cond_seq_len=2,  # dp+cond 두 스텝\n",
    "        dropout=0.2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # ── Encoder (SMILES) ───────────────────────────────────\n",
    "        self.smiles_emb = nn.Linear(vocab_size, d_model)\n",
    "        self.pe_smiles  = PositionalEncoding(d_model, dropout, max_len=enc_seq_len)\n",
    "        enc_layer = TransformerEncoderLayer(\n",
    "            batch_first=True,\n",
    "            d_model=d_model,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=d_ff,\n",
    "            dropout=dropout,\n",
    "            activation=\"gelu\"\n",
    "        )\n",
    "        self.encoder = TransformerEncoder(enc_layer, num_layers=2)\n",
    "\n",
    "        # ── Decoder (properties) ───────────────────────────────\n",
    "        self.prop_emb = nn.Linear(1, d_model)\n",
    "        self.pe_prop  = PositionalEncoding(d_model, dropout, max_len=cond_seq_len)\n",
    "        dec_layer = TransformerDecoderLayer(\n",
    "            batch_first=True,\n",
    "            d_model=d_model,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=d_ff,\n",
    "            dropout=dropout,\n",
    "            activation=\"gelu\"\n",
    "        )\n",
    "        self.decoder = TransformerDecoder(dec_layer, num_layers=2)\n",
    "\n",
    "        # ── Output head ────────────────────────────────────────\n",
    "        self.predict = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, seq_onehot: torch.Tensor, properties: torch.Tensor):\n",
    "        \"\"\"\n",
    "        seq_onehot: [B, S, vocab_size]\n",
    "        properties: [B, T, 1]   (T ≤ cond_seq_len)\n",
    "        \"\"\"\n",
    "        # Encoder\n",
    "        x = self.smiles_emb(seq_onehot)         # [B, S, d_model]\n",
    "        x = self.pe_smiles(x)\n",
    "        enc = self.encoder(x)                   # [B, S, d_model]\n",
    "\n",
    "        # Decoder input\n",
    "        tgt = self.prop_emb(properties)         # [B, T, d_model]\n",
    "        tgt = self.pe_prop(tgt)\n",
    "\n",
    "        # Decoder + predict\n",
    "        dec_out = self.decoder(tgt, enc)\n",
    "        out = self.predict(dec_out)             # [B, T, 1]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af3034a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TF(d_model = 256, vocab_size=dataset.vocab_size)\n",
    "model.cuda()\n",
    "\n",
    "lr = 3e-5\n",
    "optim = AdamW(model.parameters(), lr=lr)\n",
    "loss_fn = HuberLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628036c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9bc217c8314cc88be64f71326c8f3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch = 1200\n",
    "model.train()\n",
    "progress = tqdm(range(epoch), desc=\"Training\")\n",
    "loss_arr = list()\n",
    "real = list()\n",
    "predict = list()\n",
    "for i in progress:\n",
    "    batchloss = 0.0\n",
    "    for (smiles_enc, dec_in, dec_out) in train_dataloader:\n",
    "        optim.zero_grad()\n",
    "\n",
    "        smiles_enc = smiles_enc.to(device)\n",
    "        dec_in = dec_in.to(device)\n",
    "        dec_out = dec_out.to(device)\n",
    "\n",
    "        output = model(smiles_enc, dec_in)\n",
    "\n",
    "        loss = loss_fn.forward(output.float(), dec_out)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        batchloss += loss\n",
    "    loss_arr.append((batchloss.cpu().item() / len(train_dataloader)))\n",
    "    progress.set_description(\"loss: {:0.6f}\".format(batchloss.cpu().item() / len(train_dataloader))) # 여기는 그냥 에러 구하는 거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baff5c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolymerDataset_test(Dataset):\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        csv_path: SMILES와 속성(dp, cond)이 담긴 CSV 파일 경로\n",
    "        log_minmax_pipeline: cond 컬럼 스케일링에 사용할 sklearn 파이프라인\n",
    "        \"\"\"\n",
    "        # 1) CSV 읽기\n",
    "        df = pd.read_csv(csv_path)\n",
    "        \n",
    "        # 3) SMILES 전처리: vocab, 인덱스 맵, 시퀀스 최대 길이\n",
    "        raw_smiles = df.iloc[:, 1].tolist()\n",
    "        self.vocab = list(\"CHNOPSFIBrClc()[]=#@*+-1234567890\") + [\"_\"]\n",
    "        self.c2i = {c: i for i, c in enumerate(self.vocab)}\n",
    "        self.vdim = len(self.vocab)\n",
    "        # +1 자리는 EOS 혹은 패딩용\n",
    "        self.max_len = max(len(s) for s in raw_smiles)\n",
    "        \n",
    "        self.vocab_size = len(self.vocab)\n",
    "        # 4) 모든 SMILES를 one-hot 시퀀스로 미리 변환해 놓기\n",
    "        self.sequences = []\n",
    "        for s in raw_smiles:\n",
    "            idxs = self._smiles_to_idx(s)\n",
    "            oh = F.one_hot(idxs, num_classes=self.vdim).float()\n",
    "            self.sequences.append(oh)\n",
    "    \n",
    "    def _smiles_to_idx(self, s: str) -> torch.Tensor:\n",
    "        \"\"\"SMILES 문자열을 정수 인덱스 시퀀스로 변환 (패딩 포함)\"\"\"\n",
    "        arr = torch.full((self.max_len,), self.c2i[\"_\"], dtype=torch.long)\n",
    "        for i, ch in enumerate(s):\n",
    "            arr[i] = self.c2i.get(ch, self.c2i[\"_\"])\n",
    "        return arr\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            seq_onehot: FloatTensor [max_len, vdim]\n",
    "            dp: LongTensor [ ]\n",
    "            cond: FloatTensor [ ]\n",
    "        \"\"\"\n",
    "        return self.sequences[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c649141",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = PolymerDataset_test(\"gen.csv\")\n",
    "\n",
    "test_dataloader = DataLoader(test_data, batch_size=256, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc963b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 1])\n",
      "torch.Size([256, 1, 1])\n",
      "torch.Size([230, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all=[]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for seq_onehot in test_dataloader:\n",
    "        # seq_onehot: [B, S, V], dec: [B, 2, 1] (dp, cond)\n",
    "        seq_onehot = seq_onehot.to(device)\n",
    "        dp_true    = torch.full([seq_onehot.size(0)],0.1,dtype=torch.float32).to(device).unsqueeze(-1).unsqueeze(-1)  # shape [B]\n",
    "        print(dp_true.shape)\n",
    "\n",
    "        out = model(seq_onehot, dp_true)\n",
    "        all.append(out)\n",
    "all = torch.cat(all, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e4ef86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.366346e-03\n"
     ]
    }
   ],
   "source": [
    "cond = all.detach().cpu().numpy()\n",
    "max(cond)\n",
    "cond_rev = log_minmax_pipeline.inverse_transform(cond.reshape(-1, 1))\n",
    "print(format(max(cond_rev)[0],\"e\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b6b485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] 742개의 CONDUCTIVITY 값을 행 0~741에 덮어썼습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_202629/1237117571.py:21: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[1.58030336e-04 1.54184978e-04 1.07981940e-03 1.27358086e-04\n",
      " 1.13754300e-04 1.31085911e-03 1.05433501e-04 1.30443985e-03\n",
      " 1.34425442e-04 1.21810439e-03 1.96217865e-04 9.00662213e-04\n",
      " 8.08146549e-04 1.05411935e-04 1.33095251e-03 1.33061281e-03\n",
      " 2.42847847e-04 1.23921374e-03 1.38197807e-04 1.23761152e-03\n",
      " 1.51860688e-04 1.81177355e-04 9.09898954e-04 1.21559016e-03\n",
      " 4.61686432e-04 3.08180199e-04 1.32498716e-03 4.63795936e-04\n",
      " 1.68627987e-04 1.28186832e-03 1.09914632e-03 1.20576282e-04\n",
      " 1.23796286e-03 5.61953857e-05 2.07874211e-04 1.83248412e-04\n",
      " 1.31048332e-03 2.19194146e-04 9.05062538e-04 1.89133774e-04\n",
      " 2.94466154e-04 1.26854400e-03 1.23337115e-04 5.90032578e-05\n",
      " 1.32637750e-03 1.56679831e-04 1.27399713e-03 1.10114668e-03\n",
      " 7.68791942e-05 1.10339583e-03 9.38253579e-05 1.13046216e-03\n",
      " 1.17602765e-04 1.46281876e-04 9.40323589e-05 1.52460663e-04\n",
      " 1.04112236e-03 1.36634614e-03 1.35634746e-03 4.34644404e-04\n",
      " 1.57615752e-04 4.02845151e-04 1.16609575e-04 2.35165455e-04\n",
      " 1.14612922e-03 6.00861640e-05 9.73100396e-05 1.26161927e-03\n",
      " 1.20589370e-03 1.32112019e-03 1.30736944e-03 7.92832361e-05\n",
      " 1.26756541e-03 2.55932391e-04 4.81048337e-04 1.29388249e-03\n",
      " 5.26371703e-04 1.23157259e-03 1.22680981e-03 6.27290501e-05\n",
      " 1.28690933e-03 1.30237127e-03 9.66049993e-05 6.21315325e-04\n",
      " 7.36649163e-05 3.45088250e-04 3.13618948e-04 2.93643738e-04\n",
      " 8.98299113e-05 1.26437936e-03 1.28274201e-03 7.77708919e-05\n",
      " 8.40333305e-05 1.24224287e-03 1.29079551e-03 1.26096827e-03\n",
      " 1.31323771e-03 5.64916001e-04 1.25775055e-03 4.42709337e-04\n",
      " 6.75909105e-05 6.43183885e-05 1.12529588e-03 2.03808973e-04\n",
      " 6.88577420e-05 9.81600897e-05 1.04751671e-03 1.31444028e-03\n",
      " 7.98032925e-05 4.78261412e-04 9.12984251e-04 2.00042021e-04\n",
      " 1.25000923e-04 4.53129323e-04 1.27899135e-03 2.86113966e-04\n",
      " 2.07042831e-04 9.56289805e-05 1.30233384e-04 4.85110329e-04\n",
      " 2.22868868e-04 1.35752431e-03 3.01084394e-04 6.03207271e-04\n",
      " 9.81992343e-04 1.24283915e-03 4.69293329e-04 1.17354459e-04\n",
      " 4.14364418e-04 3.22785228e-04 9.48942179e-05 9.57912926e-05\n",
      " 1.15633663e-03 1.82236312e-04 4.31673659e-04 1.00986683e-03\n",
      " 1.27466672e-04 9.14478660e-05 1.28393294e-03 2.55114137e-04\n",
      " 1.35507889e-03 1.16747848e-04 1.00641383e-03 1.16621326e-04\n",
      " 1.51220273e-04 2.79165455e-04 6.66764754e-05 1.12180342e-03\n",
      " 4.35462047e-04 6.86674539e-05 4.77434543e-04 9.66304433e-05\n",
      " 1.25110848e-03 8.17995111e-04 1.19167636e-03 1.20117969e-03\n",
      " 1.14546076e-03 4.13666188e-04 7.34419300e-05 6.86156200e-05\n",
      " 6.63496176e-05 1.34902191e-03 9.17044643e-04 7.49399478e-05\n",
      " 9.38035810e-05 4.99576156e-04 1.05998493e-04 1.66676808e-04\n",
      " 1.53588961e-04 1.04026010e-04 1.26675644e-04 2.75067403e-04\n",
      " 1.50709195e-04 1.19750516e-03 1.54726629e-04 7.33998822e-05\n",
      " 7.53106287e-05 8.49499484e-05 1.19670306e-03 1.28799595e-03\n",
      " 5.42902271e-05 1.20341824e-03 1.48737934e-04 1.09102242e-04\n",
      " 7.44023593e-04 1.19709631e-03 1.12814968e-03 1.05736683e-04\n",
      " 4.41453565e-04 1.19646946e-04 7.48212697e-05 9.13166557e-04\n",
      " 7.22799232e-05 1.15788495e-03 1.35589551e-04 3.13866389e-04\n",
      " 8.81856540e-05 8.53356963e-04 8.37328698e-05 8.04372248e-05\n",
      " 1.22735999e-03 1.32789346e-03 1.23220193e-03 7.68343525e-05\n",
      " 5.75006357e-04 1.12914492e-03 1.07055021e-04 3.25074594e-04\n",
      " 1.26597879e-03 1.15452160e-03 9.39356047e-04 6.06151239e-04\n",
      " 8.22843140e-05 8.80128719e-05 1.32331857e-04 1.15506910e-03\n",
      " 6.71827802e-05 1.31198741e-03 7.67236488e-05 7.78949063e-04\n",
      " 3.81918479e-04 5.69996540e-04 1.07048829e-04 3.10358679e-04\n",
      " 1.25461002e-03 6.58065692e-05 1.18752345e-04 9.46253567e-05\n",
      " 3.98243894e-04 2.38872773e-04 4.41392418e-04 1.12483546e-03\n",
      " 2.60465196e-04 1.48378836e-04 1.00672019e-04 1.24981429e-03\n",
      " 8.10604615e-05 2.99418665e-04 1.35895121e-03 1.30497699e-03\n",
      " 1.61633739e-04 1.27523963e-04 1.17684191e-03 1.21828075e-03\n",
      " 9.44325366e-05 7.02029138e-05 2.01506511e-04 8.77220591e-05\n",
      " 8.94730038e-05 6.17080077e-05 1.93945569e-04 7.85430821e-05\n",
      " 1.22815452e-03 7.96551176e-05 1.11397894e-04 1.18169968e-03\n",
      " 6.04302950e-05 9.88481552e-05 1.05223218e-04 1.19908387e-03\n",
      " 1.13895505e-04 9.67536034e-05 2.70636141e-04 1.13208499e-03\n",
      " 9.19579616e-05 1.27566734e-03 1.17452822e-04 1.17624784e-03\n",
      " 8.31572397e-05 1.32880954e-03 1.31599908e-03 1.03213366e-04\n",
      " 8.73661920e-05 5.52029887e-05 1.31354167e-03 1.00032528e-04\n",
      " 1.36100512e-03 6.06199901e-04 1.16479350e-03 8.08386321e-05\n",
      " 1.11998022e-04 6.31261719e-05 7.67077800e-05 1.11593120e-03\n",
      " 8.08906407e-05 2.24887219e-04 1.13199145e-04 1.29002437e-03\n",
      " 1.13032723e-03 6.30515206e-05 6.59573852e-05 1.23445771e-03\n",
      " 1.04068436e-04 7.08135922e-05 4.28917556e-04 9.59991448e-05\n",
      " 1.21609634e-03 9.82110869e-05 1.30239374e-03 1.11258612e-03\n",
      " 7.09240558e-05 1.05584075e-03 7.22506302e-05 2.33806044e-04\n",
      " 1.23025093e-03 8.05505842e-05 7.25133927e-04 3.70977505e-04\n",
      " 1.14876311e-04 9.23495099e-05 1.16525764e-04 1.39197669e-04\n",
      " 2.41034766e-04 7.10207460e-05 1.27853150e-03 9.41149134e-04\n",
      " 1.33893464e-03 1.72541026e-04 2.86811322e-04 2.82359542e-04\n",
      " 4.06296225e-04 7.07865911e-05 1.36592673e-04 1.57584174e-04\n",
      " 7.15043352e-05 1.35189184e-04 7.94719745e-05 7.80902701e-05\n",
      " 1.29177771e-03 8.94277066e-04 1.23434234e-03 1.29008223e-03\n",
      " 2.42124224e-04 1.09665107e-03 1.14589103e-03 1.01205066e-03\n",
      " 3.14235338e-04 8.61980836e-04 1.28302048e-03 6.77791031e-05\n",
      " 1.76971007e-04 8.14950108e-05 1.19039591e-03 7.51737316e-05\n",
      " 7.31605542e-05 5.84336347e-04 8.86717869e-04 7.24745987e-05\n",
      " 7.03530095e-05 6.72364433e-04 7.04571867e-05 1.36319397e-03\n",
      " 1.19301432e-03 6.32336887e-05 1.26385922e-03 9.21231695e-05\n",
      " 1.18681253e-03 1.25107635e-03 1.22063640e-04 2.31522994e-04\n",
      " 8.93095348e-05 5.84453694e-04 4.54049557e-04 1.22159580e-03\n",
      " 6.94146322e-04 1.16477441e-03 1.20823830e-03 3.80822574e-04\n",
      " 1.04413787e-03 1.88874532e-04 6.11924261e-05 1.40102668e-04\n",
      " 1.07263157e-04 7.05613420e-05 9.91693814e-04 1.11189857e-03\n",
      " 1.17162475e-03 1.62432116e-04 9.07849535e-05 1.31809397e-03\n",
      " 9.77752716e-05 3.40451137e-04 9.97977186e-05 3.20040213e-04\n",
      " 3.64421256e-04 1.21057557e-03 1.98410838e-04 1.64096811e-04\n",
      " 9.71149930e-05 1.80917064e-04 1.13274953e-04 1.69161300e-04\n",
      " 1.26195955e-03 1.97099143e-04 2.26734599e-04 8.44779061e-05\n",
      " 1.04372599e-03 4.82077332e-04 9.11270981e-05 7.65295990e-04\n",
      " 1.27909484e-03 4.04402264e-04 7.44735371e-05 1.20289891e-03\n",
      " 5.72976642e-05 1.20942050e-03 3.22113192e-04 1.11326412e-03\n",
      " 5.31254977e-04 7.37896189e-05 7.40044998e-05 1.24054131e-04\n",
      " 4.52133478e-04 8.54793761e-05 5.79197251e-04 1.22007274e-04\n",
      " 6.55633921e-05 7.57042784e-04 1.34701678e-03 7.48297389e-05\n",
      " 7.57540547e-05 1.29514479e-03 1.89796163e-04 6.66050299e-04\n",
      " 8.04010706e-05 7.07854779e-05 1.66281505e-04 8.67284180e-05\n",
      " 6.51334558e-05 1.26294664e-03 7.22922778e-05 1.15784421e-03\n",
      " 5.92491357e-04 8.30876743e-05 1.83676588e-04 1.20576273e-03\n",
      " 8.51357996e-04 1.38221745e-04 8.45520772e-05 1.72551343e-04\n",
      " 9.52428527e-05 1.32816797e-03 8.13714461e-04 1.40828168e-04\n",
      " 1.15197920e-03 6.82385871e-05 7.39572744e-04 6.93946611e-04\n",
      " 7.07189974e-05 1.28120591e-04 1.24906277e-04 3.08793620e-04\n",
      " 4.73786466e-04 1.22006703e-03 1.75902227e-04 4.76322923e-04\n",
      " 5.83068933e-04 1.27715722e-03 1.11709174e-04 4.60353069e-04\n",
      " 1.31254829e-03 1.24558588e-04 1.45504193e-04 3.77033663e-04\n",
      " 1.21597666e-03 1.22947153e-03 9.14436532e-05 8.72863966e-05\n",
      " 7.38046438e-05 1.32900593e-03 3.48871428e-04 6.56997145e-05\n",
      " 1.14829908e-03 2.66748102e-04 1.31164724e-03 6.54021715e-05\n",
      " 7.89370752e-05 7.45875004e-05 9.10079747e-04 7.31255932e-05\n",
      " 3.82026337e-04 8.50902143e-05 1.25274551e-03 6.75982228e-05\n",
      " 1.04568654e-03 1.33938983e-03 1.15358178e-03 8.28959019e-05\n",
      " 7.06446706e-04 7.45794154e-04 8.22274742e-05 2.13934589e-04\n",
      " 1.30679796e-03 2.01533345e-04 1.14473945e-03 1.30868435e-03\n",
      " 6.30865543e-05 1.18454779e-03 1.39692798e-04 7.96054082e-04\n",
      " 7.58479699e-04 8.19444540e-04 6.56835909e-05 6.21701547e-05\n",
      " 1.29141507e-03 1.49638203e-04 8.00912530e-05 1.25852239e-03\n",
      " 1.21255987e-03 1.49345040e-04 1.98611931e-04 1.29308261e-03\n",
      " 3.16147460e-04 4.35653899e-04 9.09507726e-05 1.34710048e-03\n",
      " 1.21712364e-04 8.36590698e-05 1.27112085e-03 6.97565920e-05\n",
      " 9.98747200e-05 1.02237929e-04 6.82360478e-05 6.25108587e-05\n",
      " 6.42170853e-05 3.87129956e-04 1.25789223e-03 1.31453190e-03\n",
      " 4.43214580e-04 2.96104059e-04 4.61410644e-04 3.33423843e-04\n",
      " 1.01551425e-03 1.17684039e-03 6.67607455e-05 3.05785739e-04\n",
      " 1.06296808e-04 2.64303846e-04 2.89311400e-04 1.16273521e-04\n",
      " 6.77646094e-05 1.23843865e-03 1.02247963e-04 8.88470167e-05\n",
      " 1.95622459e-04 2.40643683e-04 1.34916336e-03 1.47333951e-04\n",
      " 1.47492348e-04 1.01509178e-03 1.04703405e-03 6.60936566e-05\n",
      " 8.99861625e-05 1.29405549e-03 1.02731858e-04 1.15852791e-03\n",
      " 4.75993555e-04 6.14098462e-05 2.22020710e-04 1.16970499e-04\n",
      " 2.61507637e-04 7.22217155e-05 1.16270711e-03 8.18629342e-04\n",
      " 7.61928211e-04 7.51204716e-05 8.22986010e-04 1.29704407e-04\n",
      " 1.12116116e-03 1.28068053e-03 3.20883701e-04 1.23496552e-03\n",
      " 1.15848554e-04 1.24662780e-04 4.82753152e-04 8.47917763e-05\n",
      " 1.41425611e-04 4.56833106e-04 1.07166066e-04 1.05288644e-04\n",
      " 6.85582490e-05 7.60728290e-05 1.08648615e-03 8.99170846e-05\n",
      " 9.83437276e-05 1.22709211e-03 2.48471653e-04 9.32316296e-04\n",
      " 8.73447425e-05 3.05755297e-04 1.11160881e-03 2.61138659e-04\n",
      " 6.43993029e-04 1.17051962e-03 6.52396848e-05 9.66691936e-04\n",
      " 2.12772313e-04 8.80179810e-04 1.96528374e-04 1.19565302e-04\n",
      " 1.35116477e-03 1.00410325e-04 7.53867644e-05 6.58699428e-05\n",
      " 2.02139490e-04 6.57015844e-05 8.15521998e-05 2.67122668e-04\n",
      " 1.16965978e-03 7.61660340e-05 9.74386567e-05 1.05209404e-03\n",
      " 3.66413733e-04 1.82700256e-04 1.23926788e-03 3.34196811e-04\n",
      " 1.30014762e-03 1.75140813e-04 9.96104791e-04 7.79946713e-05\n",
      " 2.59218272e-04 1.36421388e-03 1.28998014e-04 3.42672371e-04\n",
      " 6.89151420e-05 8.32479200e-05 8.86532507e-05 8.27466502e-05\n",
      " 3.70301888e-04 1.14361744e-03 8.56212355e-05 8.38959459e-05\n",
      " 5.35620675e-05 1.44254896e-04 6.98614094e-05 3.86865984e-04\n",
      " 3.37197853e-04 1.05411850e-03 1.13674346e-03 5.90976997e-05\n",
      " 2.30383535e-04 1.18095567e-03 3.10975593e-04 8.10199344e-05\n",
      " 1.14782895e-04 6.55657277e-05 1.26311032e-03 8.49287317e-05\n",
      " 1.06566143e-03 1.28213011e-04 7.40981995e-05 1.20146386e-03\n",
      " 1.23846089e-03 1.38309697e-04 7.13187183e-05 8.22951115e-05\n",
      " 6.25539105e-05 9.43706618e-05 1.33849552e-03 1.32180483e-03\n",
      " 3.70182242e-04 8.98715953e-05 3.35148274e-04 1.33595394e-03\n",
      " 1.26928138e-03 1.75350870e-04 2.37253669e-04 7.93473082e-05\n",
      " 1.02610553e-04 1.20036700e-03 1.57170361e-04 1.15252660e-04\n",
      " 9.61605401e-04 1.19770074e-03 9.72060778e-04 3.64850886e-04\n",
      " 8.66371556e-04 1.54182184e-04 1.64055382e-04 2.14082931e-04\n",
      " 1.04696919e-04 1.31632248e-03 1.19251455e-03 2.60797737e-04\n",
      " 1.29637381e-04 1.80695366e-04 8.19989873e-05 1.04535829e-04\n",
      " 8.90116062e-05 6.41650622e-05 1.84336794e-04 5.82337088e-05\n",
      " 1.28143595e-03 5.83439309e-04 1.17746310e-03 1.97798436e-04\n",
      " 6.66711639e-05 1.17644369e-04 8.02138456e-05 7.96085587e-05\n",
      " 6.92691247e-05 2.48143566e-04 1.25619851e-03 3.23342014e-04\n",
      " 1.01681326e-04 1.94821638e-04 4.57242015e-04 1.29118096e-03\n",
      " 6.65380721e-05 1.31566986e-03 2.54760234e-04 4.67578357e-04\n",
      " 1.10254670e-03 4.30095359e-04 4.64023644e-04 1.88256832e-04\n",
      " 8.89046423e-05 1.84762539e-04 1.10165169e-03 1.05196465e-04\n",
      " 8.59520689e-04 1.17219148e-04 1.74353641e-04 1.10279012e-04\n",
      " 1.44100632e-04 7.98109540e-05 1.81708019e-04 7.21672404e-05\n",
      " 1.14286551e-03 1.25214702e-03 1.83609183e-04 7.04933424e-04\n",
      " 1.26602117e-03 1.06728985e-04 8.58512940e-05 1.07287080e-04\n",
      " 6.16752222e-05 1.26517413e-03 1.21614430e-03 7.14409107e-05\n",
      " 9.89473338e-05 1.11067580e-04]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[start:start + n_new - 1, \"CONDUCTIVITY\"] = conds_flat\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"gen.csv\")\n",
    "\n",
    "# ② 0이 들어 있는 행 인덱스 목록\n",
    "zero_rows = df.index[df[\"CONDUCTIVITY\"] == 0].tolist()\n",
    "if not zero_rows:\n",
    "    raise ValueError(\"CONDUCTIVITY가 0인 행이 없습니다.\")\n",
    "\n",
    "# ③ 덮어쓸 시작 위치 = 첫 번째 0\n",
    "start = zero_rows[0]\n",
    "\n",
    "# ④ 덮어쓸 길이 체크\n",
    "conds_flat = np.asarray(cond_rev).flatten()\n",
    "n_new = len(conds_flat)\n",
    "\n",
    "# CSV 끝을 넘어가면 오류\n",
    "if start + n_new > len(df):\n",
    "    raise ValueError(f\"데이터 길이 부족: 0부터 {n_new}개 넣으려면 \"\n",
    "                     f\"CSV에 최소 {start + n_new}행이 있어야 합니다.\")\n",
    "\n",
    "# ⑤ 실제로 덮어쓰기\n",
    "df.loc[start:start + n_new - 1, \"CONDUCTIVITY\"] = conds_flat\n",
    "\n",
    "# ⑥ 저장\n",
    "df.to_csv(\"gen.csv\", index=False)\n",
    "print(f\"[✓] {n_new}개의 CONDUCTIVITY 값을 행 {start}~{start+n_new-1}에 덮어썼습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2945cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*][N][*]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<psmiles.psmiles.PolymerSmiles at 0x70ceaa96cfb0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PS(\"*[N+]*\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch.venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
