{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e982f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GINEConv, global_add_pool\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import HuberLoss\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import MinMaxScaler,FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import from_smiles\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "from rdkit import Chem\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "import matplotlib.pyplot as plt\n",
    "print(device)\n",
    "mm = MinMaxScaler()\n",
    "\n",
    "log_transformer = FunctionTransformer(np.log1p, validate=True)\n",
    "log_minmax_pipeline = Pipeline(steps=[\n",
    "    ('log', log_transformer),\n",
    "    ('minmax', MinMaxScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a13df51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 1. 원자·본드 피처 헬퍼\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "ATOM_LIST = [1, 6, 7, 8, 9, 15, 16, 17, 35, 53]                 # H C N O F P S Cl Br I\n",
    "NUM_ATOMS = len(ATOM_LIST) + 1                                  # +1 for \"other\"\n",
    "\n",
    "BOND_TYPES = [Chem.rdchem.BondType.SINGLE,\n",
    "              Chem.rdchem.BondType.DOUBLE,\n",
    "              Chem.rdchem.BondType.TRIPLE,\n",
    "              Chem.rdchem.BondType.AROMATIC]                    # 4 종류\n",
    "EDGE_DIM = 6                                                    # 4 + conjugated + in_ring\n",
    "\n",
    "def atom_features(atom: Chem.Atom) -> torch.Tensor:\n",
    "    \"\"\"길이 15: 10(one-hot) + degree(0-4) + aromatic + formal_charge\"\"\"\n",
    "    Z = atom.GetAtomicNum()\n",
    "    one_hot = [int(Z == a) for a in ATOM_LIST] + [int(Z not in ATOM_LIST)]\n",
    "    degree  = [int(atom.GetTotalDegree() == d) for d in range(5)]          # 0~4\n",
    "    aromatic = [int(atom.GetIsAromatic())]\n",
    "    charge   = [atom.GetFormalCharge() + 3]                                # −3~+3 → 0~6\n",
    "    charge_oh = [int(charge[0] == c) for c in range(7)]                    # 7 bins\n",
    "    return torch.tensor(one_hot + degree + aromatic + charge_oh, dtype=torch.float)\n",
    "\n",
    "def bond_features(bond: Chem.Bond) -> torch.Tensor:\n",
    "    btype = [int(bond.GetBondType() == t) for t in BOND_TYPES]            # 4\n",
    "    conj  = [int(bond.GetIsConjugated())]                                 # 1\n",
    "    ring  = [int(bond.IsInRing())]                                        # 1\n",
    "    return torch.tensor(btype + conj + ring, dtype=torch.float)           # (6,)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 2. 데이터셋\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "class PolymerDatasetPyG(Dataset):\n",
    "    \"\"\"\n",
    "    csv:\n",
    "        col1: ID    col2: SMILES    ... col5: DP    ... col7: conductivity\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_path: str):\n",
    "        super().__init__()\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # ── 2-1. 그래프-레벨 스칼라 (DP) ────────────────────────\n",
    "        dp_raw = df.iloc[:, 4].values.reshape(-1, 1)           # (N,1)\n",
    "        self.dp = torch.tensor(mm.fit_transform(dp_raw),\n",
    "                               dtype=torch.float32).squeeze(1) # (N,)\n",
    "\n",
    "        # (선택) 추가 물성 스칼라 예: conductivity\n",
    "        self.cond = torch.tensor(\n",
    "            log_minmax_pipeline.fit_transform(\n",
    "                df.iloc[:, 6].values.reshape(-1, 1)),\n",
    "            dtype=torch.float32\n",
    "        ).squeeze(1)                                           # (N,)\n",
    "\n",
    "        # ── 2-2. 그래프 생성 ──────────────────────────────────\n",
    "        self.graphs = []\n",
    "        for i, smi in enumerate(df.iloc[:, 1]):\n",
    "            mol = Chem.MolFromSmiles(smi)\n",
    "            if mol is None:\n",
    "                raise ValueError(f\"SMILES parse error: {smi}\")\n",
    "\n",
    "            # 원자 피처\n",
    "            x = torch.stack([atom_features(a) for a in mol.GetAtoms()])    # (num_nodes, 15)\n",
    "\n",
    "            # 엣지 (양방향)\n",
    "            edge_index = []\n",
    "            edge_attr  = []\n",
    "            for bond in mol.GetBonds():\n",
    "                u, v = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "                feat  = bond_features(bond)\n",
    "                # 양방향 추가\n",
    "                edge_index.extend([[u, v], [v, u]])\n",
    "                edge_attr.extend([feat, feat.clone()])\n",
    "\n",
    "            edge_index = torch.tensor(edge_index, dtype=torch.long).t()    # (2, E)\n",
    "            edge_attr  = torch.stack(edge_attr)                            # (E, 6)\n",
    "\n",
    "            data = Data(x=x,\n",
    "                        edge_index=edge_index,\n",
    "                        edge_attr=edge_attr,\n",
    "                        dp=self.dp[i].view(1),       # (1,)\n",
    "                        cond=self.cond[i].view(1),   # (1,)\n",
    "                        y=torch.zeros(1))            # placeholder; 채워 넣으세요\n",
    "            self.graphs.append(data)\n",
    "\n",
    "    # -----------------------------------------------------------------------\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.graphs[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09dcaeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Polymers = \"simulation-trajectory-aggregate_aligned.csv\"\n",
    "dataset = PolymerDatasetPyG(Polymers)\n",
    "\n",
    "train_dataloader = DataLoader(dataset, batch_size=256, shuffle=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f266ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolyGNNRegressor(nn.Module):\n",
    "    \"\"\"\n",
    "    단일 물성 회귀를 위한 polyGNN variant.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    node_dim   : 노드(feature) 차원\n",
    "    edge_dim   : 엣지(feature) 차원\n",
    "    hidden_dim : 메시지 패싱 임베딩 차원\n",
    "    num_layers : GINEConv 층 수\n",
    "    \"\"\"\n",
    "    def __init__(self, node_dim, edge_dim, hidden_dim=256, num_layers=6):\n",
    "        super().__init__()\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.bns   = nn.ModuleList()\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            in_dim = node_dim if i == 0 else hidden_dim\n",
    "\n",
    "            # GINEConv: edge_attr (연결 원자쌍 종류, 본드 차수 등) 활용\n",
    "            mlp = nn.Sequential(\n",
    "                nn.Linear(in_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "            )\n",
    "            self.convs.append(GINEConv(mlp, edge_dim=edge_dim))\n",
    "            self.bns.append(nn.BatchNorm1d(hidden_dim))\n",
    "\n",
    "        # 그래프-수준 집계: additive pooling(논문 기본 설정)\n",
    "        self.pool = global_add_pool\n",
    "\n",
    "        # DP(1차원)까지 포함 → hidden_dim+1 → 1\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim + 1, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        # data.x          : (total_nodes, node_dim)\n",
    "        # data.edge_attr  : (total_edges, edge_dim)\n",
    "        # data.dp         : (batch_size,)  – 정규화된 스칼라\n",
    "        x, edge_index, edge_attr, batch = \\\n",
    "            data.x, data.edge_index, data.edge_attr, data.batch\n",
    "\n",
    "        for conv, bn in zip(self.convs, self.bns):\n",
    "            x = conv(x, edge_index, edge_attr)   # message passing\n",
    "            x = bn(x)\n",
    "            x = F.relu(x)\n",
    "\n",
    "        g = self.pool(x, batch)                 # (B, hidden_dim)\n",
    "\n",
    "        dp = data.dp.float().view(-1, 1)        # (B, 1)\n",
    "        g  = torch.cat([g, dp], dim=1)          # (B, hidden_dim+1)\n",
    "\n",
    "        return self.head(g).squeeze(1)          # (B,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bb2961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PolyGNNRegressor(node_dim=24, edge_dim=6)\n",
    "model.cuda()\n",
    "lr=1e-3\n",
    "optim = AdamW(model.parameters(), lr=lr)\n",
    "loss_fn = HuberLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae3db9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000154:  36%|███▌      | 356/1000 [01:59<03:36,  2.98it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m     loss = loss_fn(pred, batch.cond)\n\u001b[32m     17\u001b[39m     loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[43moptim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m     batchloss += loss\n\u001b[32m     21\u001b[39m loss_arr.append((batchloss.cpu().item() / \u001b[38;5;28mlen\u001b[39m(train_dataloader)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/torch.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:485\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    481\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    482\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    483\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    488\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/torch.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:79\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     78\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     81\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/torch.venv/lib/python3.12/site-packages/torch/optim/adam.py:246\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    234\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    236\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    237\u001b[39m         group,\n\u001b[32m    238\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    243\u001b[39m         state_steps,\n\u001b[32m    244\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/torch.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:147\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/torch.venv/lib/python3.12/site-packages/torch/optim/adam.py:933\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    931\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m933\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/torch.venv/lib/python3.12/site-packages/torch/optim/adam.py:675\u001b[39m, in \u001b[36m_multi_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    670\u001b[39m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[32m    671\u001b[39m \u001b[38;5;66;03m# Use device beta1 if beta1 is a tensor to ensure all\u001b[39;00m\n\u001b[32m    672\u001b[39m \u001b[38;5;66;03m# tensors are on the same device\u001b[39;00m\n\u001b[32m    673\u001b[39m torch._foreach_lerp_(device_exp_avgs, device_grads, \u001b[32m1\u001b[39m - device_beta1)\n\u001b[32m--> \u001b[39m\u001b[32m675\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_foreach_mul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[38;5;66;03m# Due to the strictness of the _foreach_addcmul API, we can't have a single\u001b[39;00m\n\u001b[32m    678\u001b[39m \u001b[38;5;66;03m# tensor scalar as the scalar arg (only python number is supported there)\u001b[39;00m\n\u001b[32m    679\u001b[39m \u001b[38;5;66;03m# as a result, separate out the value mul\u001b[39;00m\n\u001b[32m    680\u001b[39m \u001b[38;5;66;03m# Filed https://github.com/pytorch/pytorch/issues/139795\u001b[39;00m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(beta2, torch.Tensor):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "epoch = 1000\n",
    "progress = tqdm(range(epoch), desc=\"Training\")\n",
    "\n",
    "loss_arr = []\n",
    "\n",
    "for i in progress:\n",
    "    batchloss = 0.0\n",
    "    for batch in train_dataloader:\n",
    "        batch = batch.to(device)\n",
    "        optim.zero_grad()\n",
    "\n",
    "        pred = model(batch)\n",
    "        \n",
    "        loss = loss_fn(pred, batch.cond)\n",
    "        \n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        batchloss += loss\n",
    "        \n",
    "    loss_arr.append((batchloss.cpu().item() / len(train_dataloader)))\n",
    "    progress.set_description(\"loss: {:0.6f}\".format(batchloss.cpu().item() / len(train_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "504a313a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x70b3f415b0e0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_arr, label=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a18e96b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.18334894e-04]\n",
      " [4.88385151e-04]\n",
      " [9.42956685e-05]\n",
      " [9.54922070e-05]\n",
      " [5.43740345e-04]\n",
      " [1.15239585e-03]\n",
      " [2.48680299e-04]\n",
      " [9.91514607e-05]\n",
      " [1.10393892e-04]\n",
      " [9.68728491e-05]\n",
      " [1.24421422e-04]\n",
      " [1.08589098e-04]\n",
      " [9.23440384e-05]\n",
      " [1.19476288e-04]\n",
      " [8.91375603e-05]\n",
      " [8.48892741e-05]\n",
      " [6.68386638e-05]\n",
      " [3.49691691e-04]\n",
      " [9.59757832e-04]\n",
      " [3.14180594e-04]\n",
      " [1.04483159e-04]\n",
      " [8.74101897e-05]\n",
      " [2.01779476e-04]\n",
      " [1.80478572e-04]\n",
      " [1.01828162e-04]\n",
      " [9.28002046e-05]\n",
      " [1.02626022e-04]\n",
      " [3.35840246e-04]\n",
      " [1.19602373e-04]\n",
      " [2.05383854e-04]\n",
      " [3.26929672e-04]\n",
      " [8.98226208e-05]\n",
      " [2.29451500e-04]\n",
      " [9.79043325e-05]\n",
      " [1.02332589e-04]\n",
      " [8.03341973e-05]\n",
      " [1.64782818e-04]\n",
      " [1.07598345e-04]\n",
      " [7.33329434e-05]\n",
      " [7.32362314e-05]\n",
      " [5.81005042e-05]\n",
      " [9.17953221e-05]\n",
      " [1.06048530e-04]\n",
      " [4.95226472e-04]\n",
      " [3.08270392e-04]\n",
      " [7.98612076e-04]\n",
      " [1.00990721e-04]\n",
      " [2.25868338e-04]\n",
      " [1.21513396e-04]\n",
      " [8.60869986e-05]\n",
      " [9.63056591e-05]\n",
      " [9.91753623e-05]\n",
      " [3.39461782e-04]\n",
      " [9.29256203e-05]\n",
      " [2.68569856e-04]\n",
      " [1.08071319e-04]\n",
      " [9.64336214e-05]\n",
      " [1.82859847e-04]\n",
      " [1.31384426e-04]\n",
      " [1.09836612e-04]\n",
      " [4.07732645e-04]\n",
      " [1.27205451e-04]\n",
      " [1.66210855e-04]\n",
      " [2.23457828e-04]\n",
      " [7.07796935e-05]\n",
      " [1.12971138e-04]\n",
      " [1.03019920e-04]\n",
      " [9.65158033e-05]\n",
      " [1.16764379e-04]\n",
      " [8.86356283e-05]\n",
      " [8.44457682e-05]\n",
      " [9.88230095e-05]\n",
      " [1.80629591e-04]\n",
      " [1.26274637e-04]\n",
      " [9.20322782e-05]\n",
      " [4.15619113e-04]\n",
      " [7.31555920e-05]\n",
      " [1.04966864e-04]\n",
      " [1.36259216e-04]\n",
      " [1.13272763e-04]\n",
      " [9.64647988e-05]\n",
      " [6.98832737e-05]\n",
      " [3.07097769e-04]\n",
      " [3.34695185e-04]\n",
      " [8.00571870e-05]\n",
      " [1.23900056e-04]\n",
      " [1.09654800e-04]\n",
      " [1.03599057e-04]\n",
      " [1.33368958e-04]\n",
      " [9.58208839e-05]\n",
      " [9.10445597e-05]\n",
      " [1.15137416e-04]\n",
      " [7.84301592e-05]\n",
      " [2.42763912e-04]\n",
      " [7.72422209e-05]\n",
      " [1.21764635e-04]\n",
      " [1.03549930e-04]\n",
      " [1.02827544e-04]\n",
      " [1.26383238e-04]\n",
      " [6.39297650e-05]\n",
      " [4.03657003e-04]\n",
      " [1.74394823e-04]\n",
      " [1.42624005e-04]\n",
      " [1.07424567e-04]\n",
      " [3.77199874e-04]\n",
      " [8.55567268e-05]\n",
      " [3.45084321e-04]\n",
      " [1.58405819e-04]\n",
      " [3.87488661e-04]\n",
      " [3.70531721e-04]\n",
      " [1.18214404e-04]\n",
      " [8.10352649e-05]\n",
      " [1.46085134e-04]\n",
      " [8.65573966e-05]\n",
      " [9.03559630e-05]\n",
      " [1.28216823e-04]\n",
      " [9.75759322e-05]\n",
      " [1.09691289e-04]\n",
      " [1.89507788e-04]\n",
      " [1.36311704e-04]\n",
      " [6.94479386e-05]\n",
      " [1.02510836e-04]\n",
      " [2.01887771e-04]\n",
      " [1.17070267e-04]\n",
      " [1.55692614e-04]\n",
      " [9.35207790e-05]\n",
      " [1.33154434e-04]\n",
      " [9.11991738e-05]\n",
      " [4.84569086e-04]\n",
      " [1.22670957e-04]\n",
      " [2.69955897e-04]\n",
      " [9.70503752e-05]\n",
      " [1.53047979e-04]\n",
      " [3.48077592e-04]\n",
      " [9.59268291e-05]\n",
      " [1.72782486e-04]\n",
      " [1.83238706e-04]\n",
      " [2.57792417e-04]\n",
      " [1.11180911e-04]\n",
      " [7.96959503e-05]\n",
      " [1.48807259e-04]\n",
      " [1.13229529e-04]\n",
      " [9.70637702e-05]\n",
      " [2.32351027e-04]\n",
      " [3.60639096e-04]\n",
      " [8.21147769e-05]\n",
      " [1.26458181e-04]\n",
      " [2.17620589e-04]\n",
      " [1.17989766e-04]\n",
      " [8.47053161e-05]\n",
      " [1.69217150e-04]\n",
      " [7.91936982e-05]\n",
      " [1.02626022e-04]\n",
      " [1.48188425e-04]\n",
      " [1.29541484e-04]\n",
      " [1.46829101e-04]\n",
      " [1.34179296e-04]\n",
      " [1.00036807e-04]\n",
      " [1.10970934e-04]\n",
      " [1.21412093e-04]\n",
      " [1.10258021e-04]\n",
      " [1.06406384e-04]\n",
      " [1.51030938e-04]\n",
      " [1.15611627e-04]\n",
      " [7.54389475e-05]\n",
      " [1.09682333e-04]\n",
      " [2.19683614e-04]\n",
      " [1.59157222e-04]\n",
      " [8.96667261e-05]\n",
      " [2.72010278e-04]\n",
      " [1.81993892e-04]\n",
      " [1.21382182e-04]\n",
      " [1.06930900e-04]\n",
      " [1.34574831e-04]\n",
      " [8.83290923e-05]\n",
      " [1.33592504e-04]\n",
      " [9.48465604e-05]\n",
      " [1.74523739e-04]\n",
      " [1.89950748e-04]\n",
      " [8.64599060e-05]\n",
      " [9.31261457e-05]\n",
      " [1.17131669e-04]\n",
      " [8.34478633e-05]\n",
      " [9.05208726e-05]\n",
      " [6.83616017e-05]\n",
      " [9.61602782e-05]\n",
      " [1.29671593e-04]\n",
      " [1.21920923e-04]\n",
      " [1.07895896e-04]\n",
      " [1.07657681e-04]\n",
      " [9.26372231e-05]\n",
      " [7.68860918e-05]\n",
      " [8.16407046e-05]\n",
      " [6.85520936e-05]\n",
      " [1.42358243e-04]\n",
      " [1.37932235e-04]\n",
      " [8.92972021e-05]\n",
      " [1.20214652e-04]\n",
      " [6.85942287e-05]\n",
      " [1.09861205e-04]\n",
      " [1.05536310e-04]\n",
      " [1.76995760e-04]\n",
      " [1.11354115e-04]\n",
      " [7.58392925e-05]\n",
      " [1.34988863e-04]\n",
      " [1.29085121e-04]\n",
      " [7.40872711e-05]\n",
      " [1.16380848e-04]\n",
      " [1.03630315e-04]\n",
      " [8.81327214e-05]\n",
      " [1.26332059e-04]\n",
      " [1.25498991e-04]\n",
      " [1.50568711e-04]\n",
      " [1.35437309e-04]\n",
      " [8.63615933e-05]\n",
      " [1.00568504e-04]\n",
      " [7.03572005e-05]\n",
      " [8.67164272e-05]\n",
      " [7.13968766e-05]\n",
      " [1.14547722e-04]\n",
      " [1.33009409e-04]\n",
      " [1.06346321e-04]\n",
      " [7.79635302e-05]\n",
      " [8.12958751e-05]\n",
      " [1.02605845e-04]\n",
      " [8.75128462e-05]\n",
      " [1.10048408e-04]\n",
      " [9.26113426e-05]\n",
      " [1.27492211e-04]\n",
      " [8.03363073e-05]\n",
      " [1.25960418e-04]\n",
      " [1.07002437e-04]\n",
      " [1.04389866e-04]\n",
      " [9.72426278e-05]\n",
      " [1.02110185e-04]\n",
      " [8.35944011e-05]\n",
      " [7.15858187e-05]\n",
      " [6.42661980e-05]\n",
      " [1.34573856e-04]\n",
      " [8.34240200e-05]\n",
      " [7.86878882e-05]\n",
      " [9.58192541e-05]\n",
      " [1.22856538e-04]\n",
      " [6.84994084e-05]\n",
      " [8.19286579e-05]\n",
      " [9.35246353e-05]\n",
      " [9.91587585e-05]\n",
      " [6.31952353e-05]\n",
      " [9.22763211e-05]\n",
      " [9.56723597e-05]\n",
      " [1.35691924e-04]\n",
      " [6.65280750e-05]\n",
      " [8.62996749e-05]\n",
      " [1.42890669e-04]\n",
      " [1.21211961e-04]\n",
      " [8.31687212e-05]\n",
      " [1.50222520e-04]\n",
      " [1.63936449e-04]\n",
      " [1.23517253e-04]\n",
      " [1.26714076e-04]\n",
      " [1.81847048e-04]\n",
      " [1.12971167e-04]\n",
      " [9.38916201e-05]\n",
      " [8.50572833e-05]\n",
      " [1.27881605e-04]\n",
      " [2.99659121e-04]\n",
      " [1.32117188e-04]\n",
      " [9.65449653e-05]\n",
      " [1.37215160e-04]\n",
      " [7.44110148e-04]\n",
      " [1.35882103e-04]\n",
      " [1.20155120e-04]\n",
      " [3.62160179e-04]\n",
      " [1.90431980e-04]\n",
      " [9.29182788e-05]\n",
      " [9.05353736e-05]\n",
      " [1.02161946e-04]\n",
      " [9.66361549e-05]\n",
      " [2.26474804e-04]\n",
      " [1.51462547e-04]\n",
      " [9.20870662e-05]\n",
      " [1.22339363e-04]\n",
      " [9.55604119e-05]\n",
      " [1.46127146e-04]\n",
      " [1.01726502e-04]\n",
      " [1.30715343e-04]\n",
      " [9.91632696e-05]\n",
      " [1.43318422e-04]\n",
      " [1.00375597e-04]\n",
      " [9.81353442e-05]\n",
      " [9.54764691e-05]\n",
      " [1.03549268e-04]\n",
      " [2.74842401e-04]\n",
      " [1.03965569e-04]\n",
      " [3.64111766e-04]\n",
      " [9.24554770e-05]\n",
      " [3.14113247e-04]\n",
      " [2.49583012e-04]\n",
      " [8.69205323e-05]\n",
      " [9.69116518e-05]\n",
      " [1.00523022e-04]\n",
      " [9.65393629e-05]\n",
      " [8.01591741e-05]\n",
      " [1.72757762e-04]\n",
      " [8.53583275e-04]\n",
      " [1.21103716e-04]\n",
      " [1.09701112e-04]\n",
      " [9.11542884e-05]\n",
      " [1.95595989e-04]\n",
      " [3.64858832e-04]\n",
      " [9.23147818e-05]\n",
      " [1.17509015e-04]\n",
      " [1.01145299e-04]\n",
      " [2.53655802e-04]\n",
      " [1.36069415e-04]\n",
      " [5.98500948e-04]\n",
      " [1.11790599e-04]\n",
      " [1.42038043e-04]\n",
      " [7.19077070e-04]\n",
      " [3.36748257e-04]\n",
      " [3.49234499e-04]\n",
      " [1.29585926e-04]\n",
      " [2.35869113e-04]\n",
      " [1.06810461e-04]\n",
      " [1.02967344e-04]\n",
      " [1.44769743e-04]\n",
      " [4.75915323e-04]\n",
      " [1.49071435e-04]\n",
      " [2.60419853e-04]\n",
      " [4.96524968e-04]\n",
      " [1.35945025e-04]\n",
      " [1.62708151e-04]\n",
      " [1.45796788e-04]\n",
      " [1.21706558e-04]\n",
      " [2.45889416e-04]\n",
      " [1.18914475e-04]\n",
      " [9.65600921e-05]\n",
      " [2.29851634e-04]\n",
      " [1.62197422e-04]\n",
      " [9.14790435e-05]\n",
      " [1.16033792e-04]\n",
      " [8.82879176e-05]\n",
      " [1.39967131e-04]\n",
      " [2.96629994e-04]\n",
      " [9.49780224e-05]\n",
      " [1.48552353e-04]\n",
      " [1.31853463e-04]\n",
      " [9.78296885e-05]\n",
      " [1.03835380e-04]\n",
      " [8.26759424e-05]\n",
      " [9.72127018e-05]\n",
      " [2.06956538e-04]\n",
      " [9.25539716e-05]\n",
      " [1.04145809e-04]\n",
      " [1.59584190e-04]\n",
      " [1.78111630e-04]\n",
      " [1.52077220e-04]\n",
      " [2.38860113e-04]\n",
      " [8.53453021e-05]\n",
      " [1.97035755e-04]\n",
      " [9.37865261e-05]\n",
      " [9.95075388e-05]\n",
      " [1.15037219e-04]\n",
      " [3.38980200e-04]\n",
      " [1.17780422e-04]\n",
      " [9.95206574e-05]\n",
      " [2.63545342e-04]\n",
      " [1.19921729e-04]\n",
      " [1.44943915e-04]\n",
      " [9.70342880e-05]\n",
      " [8.84052861e-05]\n",
      " [9.34663185e-05]\n",
      " [3.41826060e-04]\n",
      " [1.03270148e-04]\n",
      " [9.33889314e-05]\n",
      " [9.35837597e-05]\n",
      " [1.83404918e-04]\n",
      " [1.67053469e-04]\n",
      " [7.70055995e-05]\n",
      " [1.10985471e-04]\n",
      " [1.61853663e-04]\n",
      " [1.05197658e-04]\n",
      " [1.02605845e-04]\n",
      " [2.63470487e-04]\n",
      " [8.12250073e-05]\n",
      " [9.68018139e-05]\n",
      " [9.62558479e-05]\n",
      " [8.59488791e-05]\n",
      " [1.02532176e-04]\n",
      " [8.46913608e-05]\n",
      " [9.83747814e-05]\n",
      " [1.34440299e-04]\n",
      " [1.05263498e-04]\n",
      " [1.01309095e-04]\n",
      " [4.50629130e-04]\n",
      " [9.57530719e-05]\n",
      " [1.05665014e-04]\n",
      " [1.06550455e-04]\n",
      " [1.35145834e-04]\n",
      " [9.81461199e-05]\n",
      " [9.27135770e-05]\n",
      " [8.59993961e-05]\n",
      " [1.63128614e-04]\n",
      " [1.39321404e-04]\n",
      " [1.20090379e-04]\n",
      " [1.15486633e-04]\n",
      " [6.69041590e-04]\n",
      " [1.38556541e-04]\n",
      " [1.11752459e-04]\n",
      " [9.32581243e-05]\n",
      " [1.20356257e-04]\n",
      " [1.10423884e-04]\n",
      " [1.00795274e-04]\n",
      " [9.68107342e-05]\n",
      " [9.42433107e-05]\n",
      " [8.33535887e-05]\n",
      " [1.10314701e-04]\n",
      " [1.23533187e-04]\n",
      " [1.13820395e-04]\n",
      " [1.02388083e-04]\n",
      " [1.13521492e-04]\n",
      " [1.02600927e-04]\n",
      " [8.72485834e-05]\n",
      " [8.51658187e-05]\n",
      " [8.21227513e-05]\n",
      " [9.60112156e-05]\n",
      " [9.55864161e-05]\n",
      " [8.95049307e-05]\n",
      " [9.95382143e-05]\n",
      " [9.15500641e-05]\n",
      " [8.99912629e-05]\n",
      " [1.89423517e-04]\n",
      " [9.63572311e-05]\n",
      " [9.10432136e-05]\n",
      " [1.06120278e-04]\n",
      " [9.40690079e-05]\n",
      " [1.18303251e-04]\n",
      " [1.17562304e-04]\n",
      " [8.45092436e-05]\n",
      " [8.81811575e-05]\n",
      " [1.05660176e-04]\n",
      " [9.33464980e-05]\n",
      " [1.02605845e-04]\n",
      " [1.05324922e-04]\n",
      " [9.81632620e-05]\n",
      " [1.00927544e-04]\n",
      " [9.22907566e-05]\n",
      " [9.17600992e-05]\n",
      " [9.18915830e-05]\n",
      " [8.61129447e-05]\n",
      " [9.27427827e-05]\n",
      " [9.48498346e-05]\n",
      " [9.43047780e-05]\n",
      " [1.11557230e-04]\n",
      " [1.01898178e-04]\n",
      " [9.26384164e-05]\n",
      " [9.76958108e-05]\n",
      " [8.95553312e-05]\n",
      " [1.18065465e-04]\n",
      " [9.02916072e-05]\n",
      " [8.49981298e-05]\n",
      " [9.30105161e-05]\n",
      " [7.49030587e-05]\n",
      " [8.21600697e-05]\n",
      " [8.62288289e-05]\n",
      " [9.30372698e-05]\n",
      " [8.76693084e-05]\n",
      " [1.18281285e-04]\n",
      " [1.00671539e-04]\n",
      " [9.09618539e-05]\n",
      " [9.17026628e-05]\n",
      " [8.86980779e-05]\n",
      " [1.04282051e-04]\n",
      " [9.76114970e-05]\n",
      " [1.02154772e-04]\n",
      " [1.20968522e-04]\n",
      " [1.04887564e-04]\n",
      " [8.39398053e-05]\n",
      " [8.71241282e-05]\n",
      " [1.37886091e-04]\n",
      " [1.02228551e-04]\n",
      " [1.20242563e-04]\n",
      " [1.12773501e-04]\n",
      " [1.00266581e-04]\n",
      " [1.14885530e-04]\n",
      " [9.67148590e-05]\n",
      " [9.88752872e-05]\n",
      " [1.03733961e-04]\n",
      " [9.84781509e-05]\n",
      " [1.01630729e-04]\n",
      " [9.99128169e-05]\n",
      " [9.95630980e-05]\n",
      " [9.02267057e-05]\n",
      " [2.09998805e-04]\n",
      " [7.37100636e-05]\n",
      " [1.31356923e-04]\n",
      " [8.51083751e-05]\n",
      " [9.87513995e-05]\n",
      " [9.12551768e-05]\n",
      " [8.63476162e-05]\n",
      " [1.00439429e-04]\n",
      " [1.64751400e-04]\n",
      " [9.07241410e-05]\n",
      " [9.38599696e-05]\n",
      " [8.49981880e-05]\n",
      " [4.82541742e-04]\n",
      " [9.09295341e-05]\n",
      " [9.02148458e-05]\n",
      " [1.20609155e-04]\n",
      " [8.29318233e-05]\n",
      " [1.08543092e-04]\n",
      " [1.13618073e-04]\n",
      " [1.09984590e-04]\n",
      " [1.06925756e-04]\n",
      " [2.33058745e-04]\n",
      " [8.80689913e-05]\n",
      " [1.46679784e-04]\n",
      " [2.19939335e-04]\n",
      " [1.03970342e-04]\n",
      " [1.03685474e-04]\n",
      " [1.04431805e-04]\n",
      " [1.93342625e-04]\n",
      " [1.63149511e-04]\n",
      " [8.64260583e-05]\n",
      " [1.48053281e-04]\n",
      " [1.72826753e-04]\n",
      " [1.07844273e-04]\n",
      " [9.97574025e-05]\n",
      " [1.46533974e-04]\n",
      " [9.82149650e-05]\n",
      " [1.51304863e-04]\n",
      " [9.59873432e-05]\n",
      " [1.03743616e-04]\n",
      " [9.32794501e-05]\n",
      " [1.01309379e-04]\n",
      " [9.04085900e-05]\n",
      " [9.28039663e-05]\n",
      " [8.81716114e-05]\n",
      " [1.65935620e-04]\n",
      " [9.68743916e-05]\n",
      " [1.15845447e-04]\n",
      " [1.01237179e-04]\n",
      " [1.16648975e-04]\n",
      " [1.02605845e-04]\n",
      " [1.32945846e-04]\n",
      " [1.05767540e-04]\n",
      " [1.12126923e-04]\n",
      " [1.32310277e-04]\n",
      " [9.67810556e-05]\n",
      " [1.11658883e-04]\n",
      " [1.02156926e-04]\n",
      " [1.00100828e-04]\n",
      " [8.32723017e-05]\n",
      " [2.29958590e-04]\n",
      " [1.12693604e-04]\n",
      " [9.59532626e-05]\n",
      " [2.70566932e-04]\n",
      " [3.41915962e-04]\n",
      " [1.03896295e-04]\n",
      " [1.09972520e-04]\n",
      " [9.34948694e-05]\n",
      " [1.91189771e-04]\n",
      " [8.18346380e-05]\n",
      " [1.35289651e-04]\n",
      " [1.03922110e-04]\n",
      " [1.03250204e-04]\n",
      " [9.87595486e-05]\n",
      " [2.06431199e-04]\n",
      " [9.96353483e-05]\n",
      " [1.05879815e-04]\n",
      " [1.01870319e-04]\n",
      " [9.45750726e-05]\n",
      " [1.01051533e-04]\n",
      " [9.13877448e-05]\n",
      " [1.03068021e-04]\n",
      " [1.63181947e-04]\n",
      " [8.78525243e-05]\n",
      " [9.42371335e-05]\n",
      " [1.18952456e-04]\n",
      " [1.02862643e-04]\n",
      " [8.21936264e-05]\n",
      " [1.29794789e-04]\n",
      " [1.00000761e-04]\n",
      " [8.59392967e-05]\n",
      " [1.00104044e-04]\n",
      " [1.11236201e-04]\n",
      " [1.49686603e-04]\n",
      " [1.17015901e-04]\n",
      " [1.03536870e-04]\n",
      " [1.13171409e-04]\n",
      " [1.00168050e-04]\n",
      " [8.80361258e-05]\n",
      " [1.11312926e-04]\n",
      " [7.56582667e-05]\n",
      " [9.73870119e-05]\n",
      " [3.39410093e-04]\n",
      " [1.02108446e-04]\n",
      " [1.17579191e-04]\n",
      " [1.23258505e-04]\n",
      " [1.10787078e-04]\n",
      " [1.13643844e-04]\n",
      " [1.04157625e-04]\n",
      " [1.04683029e-04]\n",
      " [1.16133400e-04]\n",
      " [8.35090250e-05]\n",
      " [9.65071595e-05]\n",
      " [8.30033678e-05]\n",
      " [8.93973047e-05]\n",
      " [1.12759350e-04]\n",
      " [9.73621718e-05]\n",
      " [1.00953330e-04]\n",
      " [9.44113854e-05]\n",
      " [1.02605845e-04]\n",
      " [9.50689137e-05]\n",
      " [9.43765335e-05]\n",
      " [1.07781278e-04]\n",
      " [8.57201230e-05]\n",
      " [9.26255670e-05]\n",
      " [9.44699859e-05]\n",
      " [9.02342261e-04]\n",
      " [1.00635414e-04]\n",
      " [1.01987338e-04]\n",
      " [9.25293862e-05]\n",
      " [9.16798090e-05]\n",
      " [1.03515405e-04]\n",
      " [1.67537102e-04]\n",
      " [1.32387126e-04]\n",
      " [1.25539082e-04]\n",
      " [9.43017512e-05]\n",
      " [1.85810641e-04]\n",
      " [9.57634766e-05]\n",
      " [9.90271583e-05]\n",
      " [1.01361824e-04]\n",
      " [1.03315331e-04]\n",
      " [8.05072123e-05]\n",
      " [1.33731606e-04]\n",
      " [1.26635467e-04]\n",
      " [9.66990410e-05]\n",
      " [1.04085724e-04]\n",
      " [1.04830760e-04]\n",
      " [9.55231226e-05]\n",
      " [1.34928618e-04]\n",
      " [9.76237134e-05]\n",
      " [9.32167241e-05]\n",
      " [9.08802031e-05]\n",
      " [1.09298075e-04]\n",
      " [9.80417608e-05]\n",
      " [8.35105602e-05]\n",
      " [1.04529085e-04]\n",
      " [1.00363359e-04]\n",
      " [1.02827078e-04]\n",
      " [1.50899796e-04]\n",
      " [9.35883218e-05]\n",
      " [9.55588112e-05]\n",
      " [9.91406196e-05]\n",
      " [1.75981171e-04]\n",
      " [1.28069514e-04]\n",
      " [3.52139294e-04]\n",
      " [1.03285282e-04]\n",
      " [9.00475643e-05]\n",
      " [2.03362200e-04]\n",
      " [1.05440238e-04]\n",
      " [9.83867940e-05]\n",
      " [8.27061303e-05]\n",
      " [1.49239946e-04]\n",
      " [9.14697230e-05]\n",
      " [1.23213831e-04]\n",
      " [1.00138983e-04]\n",
      " [1.02447084e-04]\n",
      " [1.04414823e-04]\n",
      " [9.34528580e-05]\n",
      " [1.45245649e-04]\n",
      " [8.19320048e-05]\n",
      " [1.21535071e-04]\n",
      " [9.88407483e-05]\n",
      " [9.44181156e-05]\n",
      " [1.25031598e-04]\n",
      " [1.30587345e-04]\n",
      " [9.37212899e-05]\n",
      " [8.87045971e-05]\n",
      " [1.07189662e-04]\n",
      " [1.06008178e-04]\n",
      " [1.04226470e-04]\n",
      " [1.06522741e-04]\n",
      " [1.21212026e-04]\n",
      " [2.50230107e-04]\n",
      " [9.92910063e-05]\n",
      " [1.69158244e-04]\n",
      " [2.41000816e-04]\n",
      " [9.25221902e-05]\n",
      " [1.12347669e-04]\n",
      " [1.02605845e-04]\n",
      " [1.35633236e-04]\n",
      " [9.19131053e-05]\n",
      " [1.05220672e-04]\n",
      " [6.92729882e-05]\n",
      " [8.86975176e-05]\n",
      " [2.29450336e-04]\n",
      " [9.93847425e-05]\n",
      " [1.05152329e-04]\n",
      " [1.05905121e-04]\n",
      " [1.24110768e-04]\n",
      " [1.16789030e-04]\n",
      " [8.23816372e-05]\n",
      " [1.33507696e-04]\n",
      " [1.60988900e-04]\n",
      " [6.26678593e-05]\n",
      " [8.58092899e-05]\n",
      " [1.23089907e-04]\n",
      " [1.31902008e-04]\n",
      " [8.83364046e-05]\n",
      " [1.53334971e-04]\n",
      " [9.65389700e-05]\n",
      " [1.01662277e-04]\n",
      " [1.00214376e-04]\n",
      " [9.48518500e-05]\n",
      " [9.10739764e-05]\n",
      " [8.89923540e-05]\n",
      " [9.65593281e-05]\n",
      " [9.20235252e-05]\n",
      " [1.00154575e-04]\n",
      " [1.12877337e-04]\n",
      " [9.57466473e-05]\n",
      " [1.06687003e-04]\n",
      " [1.01789192e-04]\n",
      " [8.45128379e-05]\n",
      " [9.56416989e-05]\n",
      " [1.02605845e-04]\n",
      " [9.75813309e-05]\n",
      " [7.39576426e-05]\n",
      " [9.98006726e-05]\n",
      " [9.70834808e-05]\n",
      " [9.02104221e-05]\n",
      " [9.23473126e-05]\n",
      " [1.09210909e-04]\n",
      " [1.02788625e-04]\n",
      " [9.34416457e-05]\n",
      " [1.07561726e-04]\n",
      " [8.92090393e-05]\n",
      " [9.44185231e-05]\n",
      " [6.23359665e-05]\n",
      " [8.31355137e-05]]\n",
      "[0.0011524]\n",
      "(742, 1)\n"
     ]
    }
   ],
   "source": [
    "test_data = \"gen.csv\"\n",
    "test_dataset = PolymerDatasetPyG(test_data)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=False, drop_last=False)\n",
    "conds = torch.Tensor(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        cond = model(batch.to(device))\n",
    "        conds = torch.cat((conds,cond.cpu().view(-1)),axis=0)\n",
    "conds = conds.detach().cpu().numpy()\n",
    "conds = log_minmax_pipeline.inverse_transform(conds.reshape(-1, 1))\n",
    "print(conds)\n",
    "print(max(conds))\n",
    "print(conds.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch.venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
